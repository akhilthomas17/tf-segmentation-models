{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make lists of image and label paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#dir_imgs = \"/mnt/sda/deep_learning/CSE527_FinalProject-master/images/train\"\n",
    "dir_imgs = \"/mnt/sda/deep_learning/phase_segmentation/images/train\"\n",
    "dir_labels = \"/mnt/sda/deep_learning/phase_segmentation/images/label\"\n",
    "assert(os.path.isdir(dir_imgs))\n",
    "assert(os.path.isdir(dir_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_003.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_005.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_007.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_009.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_011.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_013.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_015.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_019.tif', '/mnt/sda/deep_learning/phase_segmentation/images/train/10_M890_Nital_LOM_1000x_021.tif']\n",
      "['/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_003.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_005.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_007.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_009.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_011.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_013.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_015.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_019.tif', '/mnt/sda/deep_learning/phase_segmentation/images/label/10_M890_Nital_LOM_1000x_021.tif']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "img_paths = sorted(glob.glob(dir_imgs + \"/*.tif\"))\n",
    "label_paths = sorted(glob.glob(dir_labels + \"/*.tif\"))\n",
    "assert(len(img_paths) ==len(label_paths))\n",
    "print(img_paths[1:10])\n",
    "print(label_paths[1:10])\n",
    "\n",
    "train_size = (556,556)\n",
    "resize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load random image and label from list of image and label paths\n",
    "import random\n",
    "from PIL import Image\n",
    "def load_rand_sample(image_paths, label_paths, shape=train_size, pil=False):\n",
    "    num_samples = len(image_paths)\n",
    "    for _ in range(num_samples):\n",
    "        ii_rand = random.randint(0,num_samples-1)\n",
    "        img_rand = Image.open(image_paths[ii_rand])\n",
    "        label_rand = Image.open(label_paths[ii_rand])\n",
    "        if resize:\n",
    "            img_rand = img_rand.resize(shape)    \n",
    "            label_rand = label_rand.resize(shape)\n",
    "        if np.array(label_rand).sum()>150:\n",
    "            break\n",
    "    if not pil:\n",
    "        return pil_to_np(img_rand, label_rand)\n",
    "    else:\n",
    "        return img_rand, label_rand\n",
    "\n",
    "def pil_to_np(img_pil, mask_pil):\n",
    "    img  = np.array(img_pil).astype(\"float32\")/255.\n",
    "    mask = np.array(mask_pil)\n",
    "    return img, mask\n",
    "\n",
    "\"\"\" Elastic transform code from https://gist.github.com/erniejunior/601cdf56d2b424757de5\"\"\"\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "def elastic_transform_git(image, alpha, sigma, order=0, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    distored_image = map_coordinates(image, indices, order=order, mode='reflect')\n",
    "    return distored_image.reshape(image.shape)\n",
    "\n",
    "\"\"\" Elastic transform code from https://gist.github.com/erniejunior/601cdf56d2b424757de5\"\"\"\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "def elastic_transform_git_mod(image, label, alpha, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "    \n",
    "    distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n",
    "    distored_label = map_coordinates(label, indices, order=0, mode='reflect')\n",
    "    return distored_image.reshape(shape), distored_label.reshape(shape)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test brightness parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a81fa9730445b0a2edeebb504bab5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='brightness_factor', max=1.0, min=-1.0, step=0.05), B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "img, _ = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def adjust_brightness(brightness_factor=(-1, 1, 0.05)):\n",
    "    aug = A.RandomBrightness(p=1)\n",
    "    img_adj = aug.apply(img, beta=brightness_factor)\n",
    "    #plt.figure(figsize=(25,25))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_adj, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    print(\"sum img:\", img.sum())\n",
    "    print(\"sum img_adj:\", img_adj.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_factor = (-0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test contrast parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd26bb4023f4cb3a23b5a51c65c2518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='contrast_factor', max=2.0, step=0.05), Button(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def adjust_contrast(contrast_factor=(0,2,0.05)):\n",
    "    aug = A.RandomContrast(p=1)\n",
    "    img_adj = aug.apply(img, alpha=contrast_factor)\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_adj, cmap=\"gray\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_factor = (0.85, 1.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test affine transformation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1a3425369746e4980dcc5de92cba18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='angle', max=30, min=-30), FloatSlider(value=0.0, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def affine_transform(angle=(-30,30,1), translate_x=(-0.2,0.2,0.05), translate_y=(-0.2,0.2,0.05), scale=(0.9,1.1,0.05)):\n",
    "    aug = A.ShiftScaleRotate(border_mode=0)\n",
    "    img_trf = aug.apply(img, angle=angle, scale=scale, dx=translate_x, dy=translate_y)\n",
    "    label_trf = aug.apply_to_mask(label, angle=angle, scale=scale, dx=translate_x, dy=translate_y)\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.imshow(label, alpha=0.3)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.imshow(label_trf, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle=30\n",
    "#translate = (50, 50)\n",
    "translate_x = 0.1\n",
    "translate_y = 0.1\n",
    "scale = (0.9,1.1)\n",
    "#shear = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-155574efd1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_trf = TF.affine(img, angle, translate, scale, shear, resample=0, fillcolor=None)\\nlabel_trf = TF.affine(label, angle, translate, scale, shear, resample=0, fillcolor=None)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dl_tf_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/labor/miniconda3/envs/dl_tf_env/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl_tf_env/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl_tf_env/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl_tf_env/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TF' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img_trf = TF.affine(img, angle, translate, scale, shear, resample=0, fillcolor=None)\n",
    "label_trf = TF.affine(label, angle, translate, scale, shear, resample=0, fillcolor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 µs ± 11.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "aug = A.Compose([A.ShiftScaleRotate(border_mode=0)])\n",
    "augmented = aug(image=img, mask=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 ms ± 58.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "aug = A.ShiftScaleRotate(border_mode=0)\n",
    "img_trf = aug.apply(img, angle=angle, scale=scale, dx=translate_x, dy=translate_y)\n",
    "label_trf = aug.apply_to_mask(label, angle=angle, scale=scale, dx=translate_x, dy=translate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test elastic transform parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21b30ab676d4060aa79430aea4e7672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='alpha'), FloatSlider(value=6.0, description='sigma', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def elastic_transform(alpha=(0,100,1), sigma=(5,7,0.01)):\n",
    "    aug = A.Compose(\n",
    "        [A.ElasticTransform(p=1, border_mode=4, alpha=alpha, alpha_affine=0, sigma=sigma, approximate=False, interpolation=0)])\n",
    "    augmented = aug(image=img, mask=label)\n",
    "    label_trf = augmented[\"mask\"]\n",
    "    img_trf = augmented[\"image\"]\n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    print(img_trf.max(), img_trf.min(), img.max(), img.min())\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_affine = 0\n",
    "alpha = 40\n",
    "sigma = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 ms ± 753 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "aug = A.Compose(\n",
    "        [A.ElasticTransform(p=1, border_mode=0, alpha=alpha, alpha_affine=alpha_affine, sigma=sigma)])\n",
    "augmented = aug(image=img, mask=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.8 ms ± 599 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "aug = A.Compose(\n",
    "        [A.ElasticTransform(p=1, border_mode=0, alpha=alpha, alpha_affine=alpha_affine, sigma=sigma, approximate=True)])\n",
    "augmented = aug(image=img, mask=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.2 ms ± 67.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "img_2, label_2 = elastic_transform_git_mod(np.array(img)[..., None], np.array(label)[..., None], alpha, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test optical distortion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8d8f2284d34377a87f682ef29fbc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='distort_limit', max=1.0, step=0.05), FloatSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "%matplotlib inline\n",
    "@interact_manual\n",
    "def optical_distortion(distort_limit=(0,1,0.05), shift_limit=(0,1,0.05)):\n",
    "    aug = A.OpticalDistortion(p=1, border_mode=4, interpolation=0)\n",
    "    img_trf = aug.apply(img, k=distort_limit, dx=shift_limit, dy=shift_limit)\n",
    "    label_trf = aug.apply_to_mask(label, k=distort_limit, dx=shift_limit, dy=shift_limit)\n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "distort_limit = 0.1\n",
    "shift_limit = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c26f8063f247e58675abeff5290201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=11, description='blur_limit', max=20, min=3), Button(description='Run In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "%matplotlib notebook\n",
    "@interact_manual\n",
    "def blur(blur_limit=(3,20,1)):\n",
    "    aug = A.Blur(p=1)\n",
    "    img_trf = aug.apply(img, ksize=blur_limit)\n",
    "    label_trf = label\n",
    "    #plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_limit = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test gaussian blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556398bf71ed45df85c2ed01c3cc71fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=11, description='blur_limit', max=20, min=3), Button(description='Run In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def gauss_blur(blur_limit=(3,20,1)):\n",
    "    aug = A.GaussianBlur(p=1)\n",
    "    img_trf = aug.apply(img, ksize=blur_limit)\n",
    "    label_trf = label\n",
    "    #plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_limit = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='var_limit', max=0.02, step=0.005), Button(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def gauss_noise(var_limit=(0,0.02,0.005)):\n",
    "    aug = A.Compose([A.GaussNoise(p=1, var_limit=var_limit)])\n",
    "    img_trf = aug(image=img)[\"image\"]\n",
    "    label_trf = label\n",
    "    #plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_limit = 0.015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test motion blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208f948281b14e0194831c3bd08c6bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='blur_limit', max=10, min=3), Button(description='Run Int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "img, label = load_rand_sample(img_paths, label_paths)\n",
    "@interact_manual\n",
    "def motion_blur(blur_limit=(3,10,1)):\n",
    "    aug = A.Compose([A.MotionBlur(p=1, blur_limit=blur_limit)])\n",
    "    img_trf = aug(image=img)[\"image\"]\n",
    "    label_trf = label\n",
    "    #plt.figure(figsize=(30,15))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_trf, cmap=\"gray\")\n",
    "    plt.imshow(label_trf, alpha=0.3)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.imshow(label, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_limit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_pytorch_env]",
   "language": "python",
   "name": "conda-env-dl_pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
